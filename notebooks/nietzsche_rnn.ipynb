{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n",
      "total chars: 57\n",
      "nb sequences: 200285\n",
      "Vectorization...\n",
      "Build model...\n",
      "Epoch 1/1\n",
      "200192/200285 [============================>.] - ETA: 0s - loss: 2.0397\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"the evil as a\n",
      "benefit of which the uses \"\n",
      "the evil as a\n",
      "benefit of which the uses and of a the present the warings the conceuse the such a the present and and by every the one the experitious and alour and completesm to a such the really not should the\n",
      "oble waster of a the has to knowledge the inflation the indiss of for but the world who have a the which the hasse the\n",
      "expect to a morality and a relight to hasse of himself to the hersely and a such a still and the soul in a con\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"the evil as a\n",
      "benefit of which the uses \"\n",
      "the evil as a\n",
      "benefit of which the uses of the pays of the\n",
      "sufferingly the his in in a goed the interple the himself all the self and soul the there acting of the concies of which oursting and which ething and all to a be the such which the self and and it be the inceltions are the supe of the hass a preys the supe the ourst and that homen of a expess of the master of the fains in a pood that it is of the hersuct to a not of the concest\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"the evil as a\n",
      "benefit of which the uses \"\n",
      "the evil as a\n",
      "benefit of which the uses that which the very\n",
      "when he as a the has repescess and to be not despresso--the sentity to himself, a the means to his esting and rengering of the portion of the german in supperit of she toure his at the herent of strich in recomes but in a not good of the interning the hases and all one to the concestion of the proted the self and interdable to a concesse, the world of the enting and shild a sou\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"the evil as a\n",
      "benefit of which the uses \"\n",
      "the evil as a\n",
      "benefit of which the uses and for it is a be to moral scile of the suppess of the subjences, is are is a the soul of the concepted the sperich of the more of the things the moral when it is be not a subfect of mudent which itself is himself and be of the every a see in the great the world a the has lome has real the regure of the inverse of the trature of the hasse the soul we the self and and it is concention of stile und\n",
      "\n",
      "200285/200285 [==============================] - 107s 532us/step - loss: 2.0395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa78815a6d8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "path = get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        def inference(params_dict, *args):\n",
    "            seed = params_dict['seed']\n",
    "            seed = seed.lower()\n",
    "            generated = seed\n",
    "            for i in range(400):\n",
    "                x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(seed):\n",
    "                    x_pred[0, t, char_indices[char]] = 1.\n",
    "                preds = model.predict(x_pred, verbose=0)[0]\n",
    "                next_index = sample(preds, 0.5)\n",
    "                next_char = indices_char[next_index]\n",
    "                generated += next_char\n",
    "                seed = seed[1:] + next_char\n",
    "            return generated\n",
    "        print(inference({'seed': sentence}))\n",
    "\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=6,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model,'/root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\": 10, \"w\": 49, \"l\": 38, \"o\": 41, \"5\": 15, \"6\": 16, \")\": 6, \"h\": 34, \"8\": 18, \"t\": 46, \".\": 9, \"k\": 37, \"d\": 30, \"!\": 2, \"\\'\": 4, \"=\": 22, \"[\": 24, \"s\": 45, \";\": 21, \"]\": 25, \"e\": 31, \",\": 7, \"\\\\\"\": 3, \"p\": 42, \"g\": 33, \"?\": 23, \" \": 1, \":\": 20, \"(\": 5, \"\\\\n\": 0, \"q\": 43, \"1\": 11, \"4\": 14, \"2\": 12, \"z\": 52, \"7\": 17, \"j\": 36, \"c\": 29, \"y\": 51, \"f\": 32, \"_\": 26, \"\\\\u00e9\": 55, \"b\": 28, \"a\": 27, \"\\\\u00e6\": 54, \"9\": 19, \"r\": 44, \"x\": 50, \"\\\\u00e4\": 53, \"v\": 48, \"n\": 40, \"i\": 35, \"u\": 47, \"-\": 8, \"\\\\u00eb\": 56, \"m\": 39, \"3\": 13}'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\": \"\\\\n\", \"1\": \" \", \"2\": \"!\", \"3\": \"\\\\\"\", \"4\": \"\\'\", \"5\": \"(\", \"6\": \")\", \"7\": \",\", \"8\": \"-\", \"9\": \".\", \"10\": \"0\", \"11\": \"1\", \"12\": \"2\", \"13\": \"3\", \"14\": \"4\", \"15\": \"5\", \"16\": \"6\", \"17\": \"7\", \"18\": \"8\", \"19\": \"9\", \"20\": \":\", \"21\": \";\", \"22\": \"=\", \"23\": \"?\", \"24\": \"[\", \"25\": \"]\", \"26\": \"_\", \"27\": \"a\", \"28\": \"b\", \"29\": \"c\", \"30\": \"d\", \"31\": \"e\", \"32\": \"f\", \"33\": \"g\", \"34\": \"h\", \"35\": \"i\", \"36\": \"j\", \"37\": \"k\", \"38\": \"l\", \"39\": \"m\", \"40\": \"n\", \"41\": \"o\", \"42\": \"p\", \"43\": \"q\", \"44\": \"r\", \"45\": \"s\", \"46\": \"t\", \"47\": \"u\", \"48\": \"v\", \"49\": \"w\", \"50\": \"x\", \"51\": \"y\", \"52\": \"z\", \"53\": \"\\\\u00e4\", \"54\": \"\\\\u00e6\", \"55\": \"\\\\u00e9\", \"56\": \"\\\\u00eb\"}'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
